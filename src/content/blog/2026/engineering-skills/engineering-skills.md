---
author: "Ian Bull"
pubDatetime: 2026-01-14
title: "In 2026, Technical Skills Are No Longer Enough"
postSlug: engineering-skills
featured: false
tags:
 - software engineering
description: "The skills that differentiated engineers for decades are becoming commoditized. What's scarce now are the skills they were never taught."
---

For decades, the path to becoming a great software engineer was clear. Master algorithms. Learn frameworks. Write clean code. Ship features. The technical skills were the hard part. Everything else was optional.

AI has quietly changed that equation.

The skills that differentiated great engineers for years are becoming commoditized. Deep technical knowledge still matters, but it is no longer enough. What is scarce now are the skills engineers were never formally taught: planning, judgment, communication, managing attention, and navigating uncertainty.

These are not new skills. Other professions have cultivated them for centuries. Law school teaches argumentation. Medical school teaches diagnosis under uncertainty. Business school teaches decision-making with incomplete information.

Engineering programs taught none of this. They did not need to. The code spoke for itself.

Now it does not.

---

## Why the Job Changed

When code was expensive to produce, engineers were valued for production. The bottleneck was getting working software out the door. Everything else could wait.

When code becomes cheap, the bottleneck shifts. AI can generate five implementations of the same feature in an afternoon. The hard part is no longer building. It is knowing what to build, recognizing when the output is wrong, and deciding which direction to pursue.

This is not a tool change. It is a role change. Engineers are becoming orchestrators, reviewers, and decision-makers. They are still accountable for what ships, but the work itself looks different.

The problem is that most engineers were never trained for this version of the job.

According to [Gartner](https://www.gartner.com/en/newsroom/press-releases/2024-10-03-gartner-says-generative-ai-will-require-80-percent-of-engineering-workforce-to-upskill-through-2027), 80% of software engineers will need to upskill by 2027 to keep pace with generative AI. The [Stack Overflow 2025 Developer Survey](https://survey.stackoverflow.co/2025/ai) found that 65% of developers now use AI coding tools at least weekly, and [JetBrains reports](https://blog.jetbrains.com/research/2025/10/state-of-developer-ecosystem-2025/) that 85% use them regularly. The tools are everywhere. The skills to use them well are not.

---

## Five Capabilities That Now Matter

What follows are five capabilities that have become essential for engineers in 2026. None of them are new. All of them were previously optional. Now they are not.

---

## Attention Management

AI agents do not run in milliseconds. They take minutes. Sometimes longer. This creates a new kind of work rhythm that most engineers have not encountered before.

The failure mode looks like this: you kick off an agent, switch to Twitter, and twenty minutes later realize the agent finished eighteen minutes ago. Or worse, the agent asked a clarifying question five minutes in, but you were deep in something else and missed it entirely.

The instinct is to blame distraction. But the deeper problem is often upstream. If you hand an agent a vague task, it will interrupt you with questions. If you hand it a clear task, it can run to completion.

The discipline is front-loading the thinking. Treat delegation to an AI agent the way you would treat delegation to a junior engineer. You would not give a junior a half-formed idea and walk away. You would write a clear specification. You would anticipate their questions. You would define what done looks like.

This takes time. It feels slower at first. But the investment pays off in uninterrupted execution.

Planning is not just an organizational discipline. It is a micro-discipline. Every agent session benefits from a few minutes of deliberate specification before you hit enter.

---

## Distributed Product Thinking

When execution was expensive, decision-making could be centralized. Product managers decided what to build. Engineers built it. The division was clean.

When execution is cheap, that division breaks down. Engineers can now try three approaches before lunch. Which one do they keep? That is a product decision. They can ship a small experiment by end of day. Is it worth shipping? That is also a product decision.

The bottleneck is no longer "can we build it?" It is "should we build it?" And that question lands on everyone now, not just the PM.

This is uncomfortable. Most engineers did not sign up to make product calls. They were hired to solve technical problems. But the job has expanded whether anyone agreed to it or not.

The solution is not to turn every engineer into a product manager. It is to bring engineers closer to the information that product decisions require. That starts with proximity to customers. The engineer who shipped the feature may be the best person to hear why it did not work. Feedback filtered through three layers of abstraction loses the texture that makes it useful.

Beyond proximity, engineers need access to usage data, business constraints, and strategic context. They need lightweight frameworks for making small bets without waiting for approval. They need clear boundaries around what they can decide independently and what requires escalation.

Military organizations and large enterprises have dealt with versions of this problem for a long time. They call it [mission command](https://en.wikipedia.org/wiki/Mission_command) or mission-type tactics. [According to U.S. Army doctrine](https://www.army.mil/article/106872/understanding_mission_command), the principle is to empower subordinate decision-making and decentralized execution appropriate to the situation.

Software teams face a similar challenge now. Conditions change faster than centralized decision-making can keep up. The teams that learn to distribute judgment effectively will move faster than those that do not.

---

## AI Native Thinking

Most engineers are using AI tools. Fewer have changed how they think because of them.

The common pattern is treating AI as a faster version of something familiar. AI as better autocomplete. AI as a smarter Stack Overflow. AI as a faster way to write boilerplate.

That framing caps the value. It misses the deeper shift.

AI native thinking means approaching problems differently from the start. Instead of asking "how do I solve this?" you ask "how do I specify this well enough that an agent can solve it?" Instead of writing code, you write intent. Instead of debugging line by line, you verify behavior at the system level.

In February 2025, AI researcher [Andrej Karpathy coined the term "vibe coding"](https://x.com/karpathy/status/1886192184808149383) to describe an approach where you "fully give in to the vibes, embrace exponentials, and forget that the code even exists." The term [became Collins Dictionary's Word of the Year for 2025](https://en.wikipedia.org/wiki/Vibe_coding). It captured something real about how the work is changing.

This requires experimentation. You cannot read your way into a new mental model. You have to try things, fail, adjust, and try again.

The obstacle is usually time. Teams feel too busy to experiment. The backlog is full. The sprint is committed. Learning feels like a luxury.

But this is the logic of dragging square wheels while someone offers you round ones. The teams that carve out time to experiment will compound their advantage. The teams that say "we do not have time" will fall behind, slowly at first, then quickly.

Organizations need to make experimentation legitimate. Not a side project. Not a Friday afternoon indulgence. A real investment with protected time and visible support from leadership.

---

## Foundational Skills

Communication. Critical thinking. Planning. Articulating ideas clearly. Structuring an argument. Evaluating evidence.

These skills are not new. They are ancient. Other professions treat them as foundational. Lawyers learn to argue. Doctors learn to diagnose. Consultants learn to structure problems.

Engineers could often skip them. Technical excellence was enough. You could be mediocre at communication and still succeed if your code was good.

That is no longer true.

If you cannot specify what you want clearly, you cannot direct an agent effectively. If you cannot think critically, you cannot evaluate agent output. If you cannot plan, you cannot front-load the thinking that makes agents useful. If you cannot communicate, you cannot participate in distributed product decisions.

The skills that were "nice to have" have become table stakes.

This is not about soft skills as a polish on top of technical ability. It is about foundational capabilities that make technical work possible in an AI-native environment.

Engineering education will eventually catch up. In the meantime, engineers need to develop these skills themselves, and organizations need to support that development explicitly.

---

## The Human Element

Software engineering is changing faster than most people expected. The profession is being redefined in real time. Everyone knows about the layoffs. Everyone has seen the predictions about what AI will automate next.

This creates anxiety. Pretending otherwise does not help.

The numbers are sobering. [A Harvard study](https://www.finalroundai.com/blog/ai-is-making-it-harder-for-junior-developers-to-get-hired) examining 285,000 U.S. firms found that when companies start using generative AI, junior employment drops by about 9 to 10 percent within six quarters. [SignalFire research](https://www.cnbc.com/2025/09/07/ai-entry-level-jobs-hiring-careers.html) found a 50% decline in new role starts by people with less than one year of post-graduate work experience between 2019 and 2024. [IEEE Spectrum reports](https://spectrum.ieee.org/ai-effect-entry-level-jobs) that U.S. programmer employment fell 27.5% between 2023 and 2025.

Some of that anxiety is rational. The junior developer pipeline is thinning. Entry-level roles are disappearing. The skills that got people into the industry may not be the skills that keep them there.

Some of that anxiety is excessive. The work is changing, but it is not disappearing. Judgment, integration, and accountability still require humans. The role is evolving, not evaporating.

But telling people "do not worry" is not support. Real support looks different.

It looks like honest acknowledgment that the future is uncertain. It looks like investment in transferable skills, not just current-role optimization. It looks like space to talk about concerns without it being seen as weakness. It looks like encouraging learning, sharing knowledge openly, and treating adaptation as a team effort rather than an individual burden.

Engineers are not just workers executing tasks. They are people navigating a profession that is shifting beneath them. Organizations that forget this will lose their best people to burnout or departure. Organizations that remember it will build loyalty and resilience.

---

## What Organizations Can Do

Individual engineers can develop these capabilities on their own. But organizations can accelerate the process or block it.

**For attention management:** Normalize planning time before agent work. Build team norms around what counts as a good secondary task while waiting for agents. Invest in tooling that surfaces completions without demanding immediate attention.

**For distributed product thinking:** Move engineers closer to customers. The person who built the feature should hear directly why it did not work. Supplement proximity with access to usage data, metrics, and strategic priorities. Create lightweight decision frameworks. Define clear authority boundaries so people know what they can decide without asking.

**For AI native thinking:** Protect experimentation time. Pair engineers who have made the mental shift with those who have not. Share failure modes openly so everyone learns from mistakes.

**For foundational skills:** Treat communication, planning, and critical thinking as core engineering skills, not soft skills. Invest in training. Recognize and reward these capabilities the same way you recognize technical excellence.

**For the human element:** Acknowledge uncertainty honestly. Invest in transferable skills. Create space to talk about career concerns. Make adaptation a collective project, not an individual problem.

---

## The Uncomfortable Truth

AI did not just give engineers new tools. It revealed that many engineers were never trained for the parts of the job that now matter most.

The good news is that these skills are learnable. People have been developing judgment, communication, planning, and focus for thousands of years. There is nothing mysterious about them.

The uncomfortable truth is that engineering will have to catch up to other professions. The era of pure technical excellence being enough is ending. What replaces it is a harder, broader, more human version of the job.

The engineers who thrive in 2026 will not be the ones who write the most code. They will be the ones who can plan, decide, communicate, learn, and stay steady while everything around them changes.

That is the job now.
